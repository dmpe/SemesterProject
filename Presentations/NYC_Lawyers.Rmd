---
title: "NYC Attorney Registrations."
author: "Dmitrij Petrov"
date: "24. 4. 2015"
output:
  html_document:
    fig_caption: yes
    fig_height: 6
    fig_width: 8
    highlight: tango
    theme: cerulean
---

## Goal
Look at the US NYC Attorney Registrations for interesting informations. 

Source of data : <https://data.ny.gov/Transparency/NYS-Attorney-Registrations/eqw2-r5nb>

## Get the data

First we load some libraries.

```{r}
library(readr)
library(stringi)
library(stringr)
library(plyr)
library(dplyr)
library(ggplot2)
library(rvest)
```

I used CSV file downloaded from their website. Using `readr` package I skip 2 columns which are low interest to me and finally present a summary statistics. Here I am going to deal with characters only.

```{r}
data.NYS <- readr::read_csv("/srv/shiny-server/SemesterProject/Data/NYS_Attorney_Registrations.csv",
                            col_types = list("Zip" = col_character(), "Zip Plus Four" = col_character(), 
                                             "Suffix" = col_skip(), "Middle Name" = col_skip()))

summary(data.NYS)
```

## Data cleansing

Because data contain blank cells, I need to replace "" (empty spaces) with NAs. Then I also rename some columns.

```{r}
data.NYS[data.NYS == ""] <- NA
colnames(data.NYS) <- c("ID", "F.Name", "L.Name", "Comp.Name", "Street_1", "Street_2", "City", "State", "Zip", "Zip_2", "Country", "County",  "Phone", "Email", "Year_Adm", "JDoA", "Law_School", "Status", "Next_Reg")
```

### What kind of email providers lawyers used to register ?

Using `stringi` package we split Email column into a matrix. Then we omit As (i.e. those cells that we replaced above) and "convert" the matrix to a data frame. Letters before @ get "NickName" column name and after @ "Organisation". Because people cannot fill in their email properly (or maybe because of <http://rickrobinson.files.wordpress.com/2012/10/it-systems.jpg>). As a result I need to use `tolower` function.

Finally using `table` function I get frequencies of email providers. [#Google](https://www.google.de/search?q=gmail+is+unique) leads.

```{r}
splitted.email <- stri_split_fixed(data.NYS$Email, "@", 2, omit_empty = NA, simplify = TRUE) 
splitted.email <- data.frame(na.omit(splitted.email))
colnames(splitted.email) <- c("NickName", "Organisation")

splitted.email <- data.frame(table(tolower(splitted.email$Organisation)))
splitted.email <- plyr::arrange(splitted.email, desc(splitted.email$Freq))
head(splitted.email, 15)
```

Not so many law firm, right. Actually just two (not counting the government itself, of course): <http://www.legal-aid.org/en/home.aspx> and <http://www.skadden.com/>. The [later one](https://en.wikipedia.org/wiki/List_of_100_largest_law_firms_by_revenue) is also the second largest law firm by revenue. The former one is not even a law office, merely a non-profit helping poor people! 

### What kind of law school did people attend ?

Here I can use same code, but what is far more interesting is that people fill in their law school totally differently. Well, I get that from the foreigners but what about "Harvard", "Harvard Law School" and "Harvard University"" (very US-centric) ...... Just look at that. I mean common... 

```{r}
law_school <- data.frame(table(tolower(data.NYS$Law_School)))
law_school <- plyr::arrange(law_school, desc(law_school$Freq))
head(law_school, 15)
```

Four lawyers even wrote "harvard 1950". Furthermore, there are e.g. 551 unique occurences of `harvard` in the `Law_School` column. The most interessting fact to me was that some people cannot even spell properly their law school name (or company they work in). I wouldn't want to go to such lawyers :(  [OMG](http://www.freemake.com/blog/wp-content/uploads/2012/08/SpellRite-1.gif)

Source for code below: <http://www.r-bloggers.com/select-operations-on-r-data-frames/>
```{r}
harvard <- law_school[grep("harvard", law_school$Var1, ignore.case=T),]
head(harvard)

newyork <- law_school[grep("new york", law_school$Var1, ignore.case=T),]
head(newyork)

brooklyn <- law_school[grep("brooklyn", law_school$Var1, ignore.case=T),]
head(brooklyn)

johns <- law_school[grep("johns|john's", law_school$Var1, ignore.case=T),]
head(johns)

# first - observations -> rows; second - variables -> columns
rbind(johns = dim(johns),brooklyn = dim(brooklyn), ny = dim(newyork), harvard = dim(harvard))

law_school[grep("new york law shool", law_school$Var1, ignore.case=T),] # FAIL
```

### Where do lawyers work ?

Sadly enought, I first need to get rid of "unique" [business entities](https://en.wikipedia.org/wiki/Types_of_business_entity#United_States), abbreviations, symbols such as '&' - ',' - '()' or totaly wrong names. The reason is that data are - as one could have seen - very raw indeed.

```{r}
data.NYS$Comp.Name <- tolower(data.NYS$Comp.Name)

stringsToCheck <- c("corporation.", "corporation", "incorporated", "corp", "corp.", "group", "gmbh", "company", "pllc", "llp", "llc", "l.l.c.", "l.l.p.", "ltd.","inc.", "inc", "plc", "p.c.", "pc", "p.a.", "l.p.", "lp", "co.", "l.p")
patTTT <- paste(stringsToCheck, collapse = '|')


# Just an idea how to proceed (Old version)

# checkAndCleanFormatting <- function(x) {
#   x <- stri_trim_both(x)  
#   for(i in 1:length(x)) {
#     if(stri_detect_regex(x[i],patTTT) == TRUE) {
#       x[i] <- stri_replace_first_regex(x[i], patTTT, "")
#     }
#   }
#   x <- stri_trim_both(x)
# }

# Much more faster version (with C behind it)
# Run the function twice for better handling of all (edge) cases
for(i in 1:2) {
  data.NYS$Comp.Name <- sapply(as.character(data.NYS$Comp.Name), function(x) {
    if ( is.na(x) == T) {
      x <- NA
    } else {
      x <- stri_replace_first_fixed(x, "&", "and")
      x <- stri_replace_last_fixed(x, "and", "")
      x <- stri_replace_last_regex(x, ",", "") 
      if(stri_detect_regex(x, patTTT) == TRUE) {
        x <- str_replace(x, patTTT, "") 
      }
      x <- stri_trim_both(x)
    }
  })
}
```

Then I create a bar plot with TOP 20 names of companies and their number of lawyers registered in New York City. Beware that not all cases are handled by the function above, e.g. there is `davis polk and wardwell london` which however is NOT counted as (/assigned to) `davis polk and wardwell`!!! Thus numbers are not exact. See below for a prime example.

```{r}
com_name <- data.frame(table(stri_trim_both(data.NYS$Comp.Name)))
com_name <- plyr::arrange(com_name, desc(com_name$Freq))
com_name$Var1 <- as.character(com_name$Var1)

com_name.plot <- ggplot(data=com_name[1:20,], aes(x=reorder(Var1, Freq), y=Freq)) 
com_name.plot <- com_name.plot + geom_bar(stat = "identity") + coord_flip(ylim= c(400,900)) + theme(
                      axis.text.y = element_text(size = 14), 
                      axis.text.x = element_text(size = 14)) 
com_name.plot <- com_name.plot + ylab("How many registered lawyers do companies have in NYC ?") + xlab("Companies")
com_name.plot <- com_name.plot + scale_y_continuous(breaks = seq(400, 900, 50))
com_name.plot
```

```{r}
companysNames <- com_name[grep("citi", com_name$Var1, ignore.case=T),]
head(companysNames, 10)
```

Most of firms in the list are law offices. But what about [Fortune 500](https://fortune.com/global500/) companies ? How many lawyers do they have? Actually I will want to select only first 100, and plot them again.

First, I will get the current 2014 list of F500, for example [here](http://www.zyxware.com/articles/4344/list-of-fortune-500-companies-and-their-websites).

```{r}
f500 <- html("http://www.zyxware.com/articles/4344/list-of-fortune-500-companies-and-their-websites") %>%
  html_node(".data-table") %>%
  html_table(header = TRUE)
f500 <- f500[1:100, ]
f500.com <- data.frame(Names = tolower(f500$Company))

```

Similar idea as above.
```{r}
f500.com$Names <- sapply(as.character(f500.com$Names), function(x) {
  if ( is.na(x) == T) {
    x <- NA
  } else {
    x <- stri_replace_first_fixed(x, "&", "and")
    x <- stri_replace_last_fixed(x, "and", "")
    if(stri_detect_regex(x, patTTT) == TRUE) {
      x <- stri_replace_last_regex(x, patTTT, "") 
    }
    x <- stri_replace_last_fixed(x, ",", "")
    x <- stri_replace_last_fixed(x, ".", "")
    x <- stri_trim_both(x)
  }
})
```

Now I will join both previous data sets - 'company names' from original data set with the list Fortune 500 companies (actually just 100).

```{r}
right.join <- right_join(com_name, f500.com, by = c("Var1" = "Names"))
right.join <- plyr::arrange(right.join, desc(right.join$Freq))
head(right.join, 15)
```

Find me some widely known companies inside the F500 and show me their number of lawyers.  

```{r}
optesa <- right.join[grep("google|apple|microsoft|att|verizon|comcast|cbs|oracle|intel|chevron|nike|facebook|amazon|directv|dish|boeing",  right.join$Var1, ignore.case=T),]
optesa
```

No bad for Google and AT&T considering its merger with [DirectTV](http://www.forbes.com/sites/greatspeculations/2015/03/25/att-directv-deal-to-attract-less-scrutiny-than-the-comcast-twc-deal/). However, let's plot them all.

```{r}
com_name2.plot <- ggplot(data=right.join[1:30,], aes(x=reorder(Var1, Freq), y=Freq)) + coord_flip(ylim= c(10,400))
com_name2.plot <- com_name2.plot + geom_bar(stat = "identity") + theme(
  axis.text.y = element_text(size = 14), 
  axis.text.x = element_text(size = 14)) 
com_name2.plot <- com_name2.plot + ylab("How many registered lawyers do companies have in NYC ?") + xlab("Companies")
com_name2.plot <- com_name2.plot + scale_y_continuous(breaks = seq(10, 400, 40))
com_name2.plot
```



## About the author 

I am student from Germany who is interested in Asia (and its small nations).

*  https://www.linkedin.com/in/dmitrijpetrov

*  https://indestat.wordpress.com/contact-me/
